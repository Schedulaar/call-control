Zunächst betrachten wir den einfacheren Fall des Problems, nämlich den in einer Kette:
Sei $(V,E)$ eine Kette mit Kapazitäten $c: E \to \set N$ und $V=\{0,\dots,n\}$, sodass für $i \in \{0,\dots,n-1\}$
eine Kante $e_i$ existiert, die die Knoten $i$ und $i+1$ verbindet.
Eine solche Kette nennen wir \todo{todo} {\em $(0, n)$-durchnummeriert}.
\begin{definition}[Gierige Ordnung]
    Auf einer Menge $P$ von Pfaden in einer Kette $(V,E)$ nennen wir eine totale Ordnung $\leq_G$ {\em gierig},
    falls sie die Pfade nach ihren Zielknoten aufsteigend ordnet, das heißt, falls
    $\forall p, q \in P \colon t_p < t_q \Rightarrow p <_G q$.
\end{definition}
Die Berechnung der Lösung erfolgt nun mit dem {\em gierigen Algorithmus}: Dieser arbeitet auf der Eingabe einer
Kette $(V,E)$ sowie einer Menge $A$ von Pfaden in $(V,E)$ in gieriger Ordnung sortiert. \todo{check sorting (p.229)}
Er bearbeitet alle Pfade in gieriger Ordnung und akzeptiert einen Pfad, falls dadurch keine der Kapazitäten
überschritten wird, ansonsten lehnt er den Pfad ab.
Nachdem alle Pfade bearbeitet wurden, endet der Algorithmus und liefert die akzeptierten Pfade als Rückgabe.
Im Folgenden bezeichne $\leq_G$ eine feste gierige Ordnung.
Jede geeignete Menge $A$ von $k$ Pfaden kann identifiziert werden durch eine Menge $\{a_1, \dots, a_k\}$ mit
$a_1 <_G \dots <_G a_k$.
Für $A=\{a_1,\dots,a_k\}$ und $B=\{b_1,\dots,b_k\}$ schreiben wir $A \leq_G B$, falls $\forall i \in \{1,\dots,k\}\colon a_i \leq_G b_i$.
Dabei nennen wir eine geeignete Menge $A$ {\em minimal}, falls für jede gleichmächtige, geeignete Menge $B$
gilt $A \leq_G B$.
\begin{lemma}[Optimalität des gierigen Algorithmus']
    \label{greedyAlgorithm}
    Existiert bei einer Menge $P$ von Pfaden einer Kette eine geeignete Teilmenge mit $k \in \set N$ Pfaden, so ist die
    Menge der ersten $k$ Pfade nach gieriger Ordnung, die der gierige Algorithmus berechnet, eine minimale Menge.
\end{lemma}
\begin{proof}
    Sei $Q_0$ eine geeignete Menge mit $k$ Pfaden.
    Wir nennen $G$ die Menge der ersten $k$ Pfade nach gieriger Ordnung, die der gierige Algorithmus berechnet, und
    transformieren $Q_0$ schrittweise zu $Q_k = G$.
    Dabei soll für $i \in \{1,\dots\,k\}$ gelten, dass $Q_i$ geeignet ist sowie $Q_i \leq_G Q_{i-1}$.
    Dadurch ist auch $G$ geeignet und durch die Transitivität von $\leq_G$ auf Mengen von Pfaden folgt auch $G \leq_G Q_0$,
    also insbesondere die Minimalität von $G$.

    Als weitere Invariante nehmen wir auf, dass die ersten $i$ Pfade (in gieriger Ordnung) von $Q_i$ mit denen von $G$
    übereinstimmen.
    Für $i=0$ gelten alle Voraussetzungen.
    Nehmen wir also an, $Q_{i-1}$ sei geeignet und stimme auf den ersten $i-1$ Pfaden mit $G$ überein.
    Wir benennen $p$ als den $i$-ten Pfad von $G$.

    Für den Fall $p \in Q_{i-1}$ ist $p$ auch bereits der $i$-te Pfad von $Q_{i-1}$, da der Algorithmus nach
    gieriger Ordnung vorgeht und $Q_{i-1}$ mit $G$ auf den ersten $i-1$ Pfaden übereinstimmmt.
    Setzt man $Q_i \colonequals Q_{i-1}$ so bleiben alle Invarianten erhalten.

    Sonst gilt $p \notin Q_{i-1}$ und die Menge der Pfade $q \in Q_{i-1}$ mit $q >_G p$ ist nicht leer.
    Von diesen Pfaden sei $q$ ein solcher mit kleinstem Startknoten, der an $j$-ter Stelle in $Q_{i-1}$ steht
    ($j \geq i$).
    Setzen wir nun $Q_{i} \colonequals Q_{i-1} \setminus \{ q \} \cup \{ p \}$, so stimmen $Q_{i}$ und $G$ an den
    ersten $i$ Stellen wieder überein und alle Pfade, die in $Q_{i-1}$ an den Stellen $i$ bis $j-1$ stehen, rutschen
    in $Q_i$ eine Stelle weiter an die Positionen $i+1$ bis $j$.
    Insbesondere gilt also $Q_i \leq_G Q_{i-1}$.
    Bleibt zu zeigen, dass $Q_i$ wieder geeignet ist:
    Die Kanten, die links des Anfangsknoten $s_q$ von $q$ stehen, sind nicht betroffen, da aufgrund der Minimalität
    von $s_q$ dort nach $q$ keine weiteren Kapazitäten benötigt werden.
    Ist $s_q$ kleiner als der Anfangsknoten $s_p$ von $p$, so sparen die Kanten zwischen $s_q$ und $s_p$ sogar eine
    Kapazität ein.
    Ist andersrum $s_p$ kleiner als $s_q$, verletzt $Q_i$ auf den Zwischenkanten trotzdem keine Kapazitäten, da
    hier nach $p$ aufgrund der Minimalität von $s_q$ keine weiteren Pfade eine Kapazität verbrauchen und $p$ vom
    Algorithmus akzeptiert wurde, weil bis zum Pfad $p$ keine Kapazität verletzt wurde.
    Die Kanten, bei denen sich $p$ und $q$ überschneiden, spielen offensichtlich keine Rolle und die Kanten
    vom Zielknoten von $p$ bis zum Zielknoten von $q$ benötigen wieder eine Kapazität weniger.
\end{proof}

Daraus folgt, dass der gierige Algorithmus das Call-Control-Problem in Ketten löst:
Sei $Q$ eine Lösung, also eine möglichst große, geeignete Teilmenge von Pfaden in $P$, so liefert der gierige
Algorithmus nach Lemma~\ref{greedyAlgorithm} eine gleichmächtige, sogar minimale Lösung.

Eine einfache Implementierung dieses Algorithmus' könnte in $O(m \cdot n)$ erfolgen, wobei $m$ die Anzahl der gegebenen
Pfade und $n$ die Anzahl der Knoten ist, indem einfach für jeden Pfad einzeln an jeder Kante überprüft wird, ob durch
die Hinzunahme die Kapazität überschritten würde.
Jedoch lässt sich dieser Zeitaufwand sogar auf $O(m)$ verringern, wie wir in den nächsten Lemmata \todo{LEMMATA}
erkennen werden.
Dabei werden wir zunächst einen Algorithmus betrachten, bei dem vorausgesetzt wird, dass alle Kanten die gleiche
Kapazität haben, und werden diesen danach an unser Ausgangsproblem anpassen.

\subsection{Gieriger Algorithmus für gleiche Kapazitäten von Carlisle und Lloyd}\label{subsec:algorithmusGleicheKapazitäten}
Wir gehen davon aus, dass $(V,E)$ eine Kette ist, $P$ eine Menge von $m$ Pfaden in $(V,E)$ und jede Kante in $E$ nun eine
feste Kapazität $C \in \set N$ besitzt.
Dabei können wir ohne Beschränkung der Allgemeinheit von $C \leq m$ ausgehen.
Die Idee des Algorithmus besteht darin, die akzeptierten Pfade nach gieriger Ordnung in $C$ verschiedene Farben zu
färben.

Dabei wird zu jeder Farbe der aktuelle {\em Anführer} gespeichert, das heißt, der in gieriger Ordnung größte, bereits
verarbeitete Pfad mit der Farbe.
Der Algorithmus verarbeitet alle Pfade in gieriger Ordnung und sucht für jeden Pfad $p$ den größten Anführer, der
sich nicht mit $p$ überschneidet.
Ein solcher Pfad heißt {\em optimaler Anführer von $p$}.
Findet er einen solchen, wird $p$ akzeptiert, in die Farbe seines optimalen Anführers gefärbt und damit neuer Anführer
der Farbe.
Findet er keinen, gibt es keine freie Farbe, das heißt das Akzeptieren des Pfades würde eine Kapazität verletzen und der
Pfad wird abgelehnt.
Eine solche Färbung mit $C = 2$, kann man in Abbildung \todo{ABBILDUNG} sehen.

\todo{FIGURE C-COLORING}

Speichert man allerdings zu jeder Farbe einfach den jeweiligen Anführer direkt ab, würde das Berechnen eines optimalen
Anführers für jeden Pfad mindestens $O(\log C)$ benötigen und damit würden wir das Ziel einer gesamt-linearen Laufzeit
$O(m)$ verpassen.

Stattdessen verwenden Carlisle und Lloyd in ihrem Algorithmus eine spezielle Union-Find-Instanz, die sog.
Static-Tree-Set-Union-Instanz, bei der die möglichen Vereinigungen bereits zu Beginn feststehen und in einem Baum
dargestellt werden können, wodurch \todo{check} $m$ find- und $n$ union-Aufrufe in einer Laufzeit von $O(m + n)$ erfolgen können.
\todo{Referenz A Linear-Time Algorithm for a Special Case of Disjoint Set Union HAROLD N. GABOW, On the k-coloring of intervals Martin C. Carlisle”, Errol L. Lloydb3*}

Genauer führt der Algorithmus zuerst $C$ weitere sogenannte {\em virtuelle Pfade} ein, die in gieriger Ordnung
vor den eigentlichen Pfaden $P$ stehen und die initialen Anführer der $C$ Farben sind.
In gieriger Ordnung an erster Stelle (noch vor den virtuellen Pfaden) wird ein weiterer {\em fiktiver Anführer}
eingefügt, der die \todo{Darstellung} nicht-akzeptierter Pfade ermöglicht.
Zu Beginn ist jeder Pfad in einer eigenen Gruppe der Union-Find-Struktur.
Wir erhalten folgende Invarianten:
Der Repräsentant jeder Gruppe entspricht immer dem kleinsten Pfad (in gieriger Ordnung) innerhalb der Gruppe.
Ist ein Pfad noch nicht verarbeitet, so ist er in einer Einzelgruppe - die virtuellen Pfade und der fiktive Anführer
zählen jedoch bereits als verarbeitet.
Jede andere, sogenannte {\em aktive Gruppe} enthält nur (in gieriger Ordnung) aufeinanderfolgende Pfade.
Der Repräsentant einer aktiven Gruppe ist dabei entweder ein Anführer einer Farbe oder der fiktive Anführer.
Dementsprechend gibt es zu jeder Zeit genau $C+1$ aktive Gruppen, wobei die Gruppe des fiktiven
Anführers immer die kleinste Gruppe bleibt.

Zunächst berechnet der Algorithmus zu jedem Pfad $p \in P$ den {\em bevorzugten Anführer von $p$}, also den größten Pfad
in gieriger Ordnung, dessen Zielknoten gleich oder vor dem Anfangsknoten von $p$ ist.
\todo{check this:}
Das kann man mit einfachem Durchlaufen aller Endpunkte in $P$ in aufsteigender Reihenfolge erreichen, also in $O(n)$
Zeit.
Es ist offensichtlich, dass kein optimaler Anführer von $p$ in gieriger Ordnung größer als der bevorzugte Anführer von
$p$ sein kann.

Der Algorithmus bearbeitet danach jeden Pfad $p \in P$ nach gieriger Reihenfolge, wobei er jeweils wie folgt vorgeht.
Es wird der bevorzugte Pfad $q$ von $p$ betrachtet:
Ist $\find(q)$, also der Repräsentant der Gruppe von $q$, der fiktive Anführer $f$, so gibt es keinen optimalen Anführer
zu $p$, da auch alle Pfade in $P$, die kleinergleich dem bevorzugten Pfad $q$ und damit Kandidaten für einen optimalen
Anführer von $p$ wären, auch in der Gruppe von $f$ liegen und damit kein Anführer einer Farbe dabei ist, da diese die
Repräsentanten der anderen C Gruppen sind.
Daher wird $p$ abgelehnt und die Gruppe von $p$ mit der Gruppe des Vorgängers von $p$ in gieriger Ordnung vereinigt.
Die Invarianten bleiben erhalten, da wieder $C+1$ Gruppen unter den verarbeiteten Pfaden existieren mit den gleichen
Anführern.

Ist $\find(q)$ jedoch ein Anführer einer Farbe, so ist es mit Sicherheit der optimale Anführer von $p$, da es der größte
Anführer ist, der noch kleinergleich dem bevorzugten Anführer von $p$ ist (da die Pfade in den Gruppen
aufeinanderfolgend sind).
Also wird $p$ akzeptiert, in dieser Farbe gefärbt und damit neuer Anführer der Farbe.
Da $\find(q)$ nun kein Anführer mehr ist, wird seine Gruppe aufgelöst und mit der Gruppe des Vorgängers von $\find(q)$
vereinigt.
Wieder erhalten wir alle Invarianten.

Eine genauere Analyse dieses Verfahrens und dessen Laufzeit $O(m)$ beschreiben \todo{Carlisle und Llyod in 'On the
k-coloring of intervals'}.

\subsection{Gieriger Algorithmus mit willkürlichen Kapazitäten}\label{subsec:anpassenAnWillkürlicheKapazitäten}

Nachdem wir nun eine Lösung für identische Kapazitäten gefunden haben, wollen wir nun das eigentliche Problem mit
willkürlichen Kapazitäten $c: E \mapsto \set N$ durch eine geschickte Anpassung des Algorithmus' lösen.
Sei $C \colonequals \max_{e \in E} c(e)$ die maximale Kapazität aller Kanten.
Die Idee ist es, das Problem mit identischer Kapazität $C$ anzuwenden und dabei für jede Kante $e$ die $C - c(e)$
hinzugewonnen Kapazitäten mit Platzhalterpfaden zu befüllen.
Werden vom Algorithmus alle Platzhalterpfade akzeptiert, so können wir sicher sein, dass wir nach Entfernen der
Platzhalterpfade eine optimale Lösung für willkürliche Kapazitäten gefunden haben.
Wir müssen also insbesondere dafür sorgen, dass all unsere Platzhalter eingefärbt werden.

Wir beschäftigen uns zunächst näher mit dem Hinzufügen der Platzhalter:
\todo{das machen wir eigentlich immer: (links, rechts)}Dabei gehen wir von einer Kette aus mit den Knoten $V=\{v_0,\dots,v_{n-1}\}$ und den Kanten
$E=\{e_1,\dots,e_{n-1}\}$, wobei $e_i$ die Knoten $v_{i-1}$ und $v_i$ verbindet.
Wir durchlaufen nun die Kette von links nach rechts und berechnen dabei, wie viele Platzhalterpfade an jedem Knoten
beginnen bzw. enden müssen (siehe \todo{FIGURE}):
Beim ersten Knoten $v_0$ müssen $C - c(e_1)$ Platzhalterpfade beginnen und wir schreiben $(C - c(e_1))$ mal $v_1$ in einen
leeren Keller $K$.
Beim Knoten $v_i$ wird, falls $c(e_i) > c(e_{i+1})$, $v_i$ genau $(c(e_i) - c(E_{i+1}))$ mal in K gelegt.
Ist $c(e_i) < c(e_{i+1})$, so werden $c(e_{i+1}) - c(e_i)$ Elemente aus K geholt, die jeweils als Anfangspunkt mit $v_i$
als Endpunkt einen der Platzhalterpfade ergeben.
Beim letzten Knoten $v_{n-1}$ werden dann alle verbleibenden Knoten aus K mit $v_{n-1}$ als Platzhalter hinzugenommen.

Da wir allerdings insgesamt eine Laufzeit von $O(m)$ zum Ziel haben, können wir das \todo{vorangegangene} Verfahren
nicht einfach übernehmen:
Bei starken Schwankungen der einzelnen Kapazitäten kann es hier passieren, dass bis zu $\Omega(m\cdot n)$
Platzhalter hinzugefügt werden müssen, was unsere Ziellaufzeit übersteigt (siehe \todo{FIGURE}).
Jedoch wird schnell ersichtlich, dass in solchen Fällen viele Platzhalter unnötigerweise platziert werden:
Hat beispielsweise die Nachfolgekante eines Knoten $v$ eine sehr hohe Kapazität, wobei die Vorgängerkante nur eine sehr
niedrige Kapazität besitzt, so müssten extrem viele Pfade den Anfangsknoten $v$ haben, um die Kapazität der
Nachfolgekante auszunutzen.
Da wir die Pfade bereits kennen, können wir also in vielen Fällen die Kapazität von solchen Nachfolgekanten verringern und
damit Schwankungen in den Kapazitäten etwas ausgleichen.

Um diese Erkenntnis umzusetzen, definieren wir eine neue Kapazitätsfunktion $c'$ mit $c'(e_0) = \min(c(e_0), n_0)$ und
$ c'(e_i) \colonequals \min(c(e_i), c'(e_{i-1}) + n_i)$ für $i \geq 1$ , wobei $n_i$ die Anzahl der Pfade in P mit
Anfangsknoten $v_i$ ist.
Diese können wir in $O(n + m) = O(m)$ Zeit berechnen: Dazu gehen wir für jeden Knoten $v_i$ solange durch die sortierte
\todo{Liste der Endknoten aller Pfade}, bis wir alle Pfade mit Anfangsknoten $v_i$ gesehen haben, womit wir
$n_i$ wissen und $c'(e_i)$ berechnen können.
Durch das Verwenden von $c'$ statt $c$ wird die Lösung des Problems auch nicht verändert, da nur Kapazitäten entfernt
werden, die durch die Pfade P sowieso nicht nutzbar gewesen wären. Insbesondere ist also jede geeignete Menge mit den
Kapazitäten c auch eine geeignete Menge mit den Kapazitäten c'.
Das nächste Lemma soll nun aufklären, ob unser Vorgehen die Anzahl an Platzhaltern ausreichend verringern konnte:

\begin{lemma}
    Mit den neuen Kapazitäten $c'$ werden nur noch O(m) Platzhalterpfade erzeugt.
\end{lemma}
\begin{proof}
    \todo{check n-1}
    Wir betrachten den Gesamtzuwachs der Kapazitäten $I = \sum_{i = 0}^{n-1} I_i$ als Summe aller Zuwächse $I_i$ am
    Knoten $v_i$ mit $I_0 = c'(e_0)$ und $I_i = \max\{c'(e_i) - c'(e_{i-1}), 0\}$ für $i \geq 1$.
    Ein Anstieg von $c'$ in $e_i$ um $I_i \in \set N_0$ bedeutet, dass $n_i \geq I_i$, da per Definition
    $c'(e_i) \leq c'(e_{i-1}) + n_i$.
    Insbesondere ist also $I$ beschränkt durch die Anzahl an Pfaden $m$.
    Ein Platzhalterpfad wir außerdem nur dann erzeugt, wenn der Algorithmus auf einen Zuwachs in den Kapazitäten stößt
    oder das Ende der Kette erreicht ist.
    Das heißt es werden höchstens $I + C = O(m)$ Platzhalterpfade erzeugt.
\end{proof}

Insbesondere gelingt also die Anpassung der Kapazitäten, sowie das Auffüllen mit Platzhalterpfaden in $O(m)$ Zeit.
Nun müssen wir uns nur noch der Herausforderung stellen, beim Lösen des Problems mit identischen Kapazitäten alle
Platzhalter zu akzeptieren.
Die Idee dabei ist, die Platzhalterpfade so früh wie möglich zu akzeptieren, und erst danach alle anderen Pfade zu
betrachten.

Dazu bilden wir zuerst eine \todo{Liste $L$ der Endknoten aller Pfade} (inklusive Platzhalterpfade), die die Knoten
aufsteigend und bei gleichen Knoten Zielknoten vor Anfangsknoten sortiert.
Dabei kommt jeder Knoten sooft vor, wie es Pfade mit ihm als einer der beiden Endknoten gibt.
Die gierige Ordnung $\leq_{G}$ erhalten wir, indem wir in der Liste jeden Zielknoten eines Pfades durch den Pfad selbst
ersetzen und die restlichen Knoten verwerfen.

Wir benutzen mit dem fiktiven Anführer und den $C$ virtuellen Pfaden wieder dieselbe Hilfspfade wie in
Abschnitt~\ref{subsec:algorithmusGleicheKapazitäten}, wobei diese in $\leq_G$ wieder vor den restlichen Pfaden stehen.
Für die Berechnung der bevorzugten Anführer jedes Pfades $p$ (also dem in $\leq_G$ größten Pfad, dessen
Zielknoten kleinergleich dem Anfangsknoten von $p$ ist) benötigen wir mit $\leq_G$ ebenfalls einen Zeitaufwand von
$O(m)$.
Auch die Union-Find-Struktur bleibt die gleiche und jeder Pfad startet in seiner eigenen Gruppe.
Nun iteriert der Algorithmus durch L und verarbeitet dabei Platzhalterpfade beim Antreffen vom
Anfangsknoten und tatsächliche Pfade beim Antreffen vom Zielknoten.
Die eigentliche Verarbeitung eines Pfades $p$ hat sich aber nicht geändert: Es wird der bevorzugte Pfad $q$ von $p$
betrachtet; falls $\find(q)$ der fiktive Anführer ist, wird $p$ abgelehnt und die Gruppe von $p$ mit der
Gruppe des Vorgängers von $p$ in gieriger Ordnung vereinigt; andernfalls wird p akzeptiert, in der Farbe von $\find(q)$
gefärbt und die Gruppe von $\find(q)$ mit der Gruppe seines Vorgängers in gieriger Ordnung vereinigt.

Das nächste Lemma soll nun zeigen, dass das Auffüllen mit Platzhaltern zusammen mit diesem Verfahren eine korrekte
Implementierung des gierigen Algorithmus' darstellt:

\begin{lemma}
    Der \todo{vorangehende} Algorithmus entspricht dem gierigen Algorithmus.
\end{lemma}
\begin{proof}
    Wir benennen $U$ als den vorangehenden Algorithmus.
    Für $U$ haben wir wieder folgende Invariante für die Union-Find-Gruppen:
    Jede Gruppe mit verarbeiteten Pfaden enthält nur in $\leq_G$ aufeinanderfolgende Pfade und der Repräsentant einer
    solchen Gruppe ist entweder ein Anführer einer Farbe oder der fiktive Anführer.
    Andere Gruppen sind Einzelgruppen.
    Insbesondere berechnet $U$ wieder eine \todo{C-färbbare Teilmenge der Pfade}.
    Dadurch, dass die Platzhalterpfade bereits an den Anfangsknoten verarbeitet werden, haben diese immer einen farbigen
    Anführer, da sie entsprechend den Kapazitäten gewählt wurden.
    Damit wird ersichtlich, dass zumindest alle Platzhalterpfade akzeptiert werden.
    Jetzt müssen wir noch zeigen, dass genau die tatsächlichen Pfade akzeptiert werden, die der gierige Algorithmus
    ebenfalls akzeptiert.

    Dazu gehen wir vom Gegenteil aus und betrachten den ersten tatsächlichen Pfad $p$ in gieriger Ordnung, bei dem die
    Entscheidung unterschiedlich ausgefallen ist.
    Da wir von $U$ bereits wissen, dass er eine C-Färbung mit allen Platzhalterpfaden durchführt, sind
    seine akzeptierten Pfade eine geeignete Menge für das Call-Control-Problem.
    Da der gierige Algorithmus immer eine minimale Lösung liefert, muss $p$ vom gierigen Algorithmus akzeptiert und von
    $U$ abgelehnt worden sein.
    Ist $A$ die Menge der Pfade, die bisher (von beiden Verfahren) akzeptiert wurden.
    Da der gierige Algorithmus zusätzlich $p$ akzeptiert hat, wissen wir, dass $A \cup \{p\}$ geeignet ist, was wir
    im Folgenden zum Widerspruch führen:
    Da $U$ $p$ am Zielknoten verarbeitete (und $p$ damit der aktuell größte Pfad in gieriger Ordnung
    war), mussten sich zu dieser Zeit alle Anführer von Farben mit $p$ überschnitten haben.
    Dabei sei $l$ der in gieriger Ordnung kleinste Anführer einer Farbe und $e$ die letzte Kante seines Pfades.
    Von dieser wissen wir sicher, dass sie sich mit $p$ überschneidet.

    Angenommen, es existiere eine Farbe $c^*$, sodass kein Pfad in dieser Farbe $e$ enthält. Da $l$ der kleinste Anführer
    ist, existiert ein Pfad $p_1$ in $c^*$ links von $e$ und ein Pfad $p_2$ in $c^*$ rechts von $e$.
    Wählt man diese jeweils möglichst nah an $e$, so erkennt man einen Widerspruch, da als $p_2$ mit $p_1$ als den
    scheinbar optimalen Anführer in $c^*$ gefärbt wurde, war tatsächlich $l$ ein besserer Anführer von $p_2$.

    Also besitzen alle $C$ Farben einen Pfad, der $e$ enthält, insgesamt gibt es also $C+1$ Pfade in $A \cup \{p\}$, die
    $e$ enthalten. Das ist allerdings ein Widerspruch dazu, dass $A \cup \{p\}$ eine geeignete Menge ist.
\end{proof}













