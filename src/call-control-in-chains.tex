Dieser Abschnitt analysiert den einfacheren Fall des Problems, nämlich den in einer Kette:
Sei $(V,E)$ eine Kette mit Kapazitäten $c: E \to \set N$ und $V=\{0,\dots,n-1\}$, sodass für $i \in \{0,\dots,n-2\}$
die Kante $e_i$ die Knoten $i$ und $i+1$ verbindet.
Außerdem sei eine Menge $P$ von Pfaden in $(V,E)$ gegeben.
\begin{definition}[Gierige Ordnung]
    Auf einer Menge $P$ von Pfaden in einer Kette nennen wir eine Totalordnung $\leq_G$ mit zugehöriger strenger Totalordnung
    $<_G$ {\em gierig},
    falls sie die Pfade nach ihren Zielknoten aufsteigend ordnet, das heißt, falls
    $\forall p, q \in P \colon t_p < t_q \Rightarrow p <_G q$.
\end{definition}
Im Folgenden bezeichne $\leq_G$ eine feste gierige Ordnung auf $P$.
Die Berechnung der optimalen Lösung für \CallControl\ in der Kette erfolgt mit dem {\em gierigen Verfahren}:
Dieses nimmt an, dass die Pfade $P$ bereits in gieriger Ordnung $\leq_G$ sortiert sind,
und verwaltet eine Menge der von ihm akzeptierten Pfade, die zu Beginn leer ist.
Es bearbeitet alle Pfade in der gegebenen Sortierung und fügt einen Pfad zu den akzeptierten Pfaden hinzu, falls die
akzeptierten Pfade dadurch keine der Kantenkapazitäten verletzen, das heißt, falls die akzeptierten Pfade eine zulässige Menge bleiben.
Ansonsten wird der Pfad abgelehnt.
Nachdem alle Pfade bearbeitet wurden, endet das Verfahren mit den akzeptierten Pfaden als Rückgabe.

Jede Menge $A \subseteq P$ von $k$ Pfaden kann als eine Menge $\{a_1, \dots, a_k\}$ dargestellt werden mit
$a_1 <_G \dots <_G a_k$.
Für solche $A=\{a_1,\dots,a_k\}$ und $B=\{b_1,\dots,b_k\}$ schreibe man dann $A \leq_G B$, falls $\forall i \in \{1,\dots,k\}\colon a_i \leq_G b_i$.
Dabei nennen wir eine zulässige Menge $A$ {\em minimal}, falls $A \leq_G B$ für jede gleich-mächtige, zulässige Menge $B$.
\begin{lemma}[Optimalität des gierigen Verfahrens]\label{lem:optimalityGreedyAlgorithm}
    Existiert bei einer Menge $P$ von Pfaden einer Kette eine zulässige Teilmenge mit $k \in \set N$ Pfaden, so ist die
    Menge der in gieriger Ordnung $\leq_G$ kleinsten $k$ Pfade, die das gierige Verfahren berechnet, eine minimale Menge.
\end{lemma}
\begin{proof}
    Sei $Q_0$ eine zulässige Menge mit $k$ Pfaden.
    Wir nennen $G$ die Menge der in $\leq_G$ kleinsten $k$ Pfade, die das gierige Verfahren berechnet, und
    transformieren $Q_0$ schrittweise zu $Q_k = G$.
    Dabei soll für $i \in \{1,\dots\,k\}$ gelten, dass $Q_i$ zulässig ist sowie $Q_i \leq_G Q_{i-1}$.
    Dadurch ist auch $G$ zulässig und durch die Transitivität von $\leq_G$ auf Mengen von Pfaden folgt $G \leq_G Q_0$,
    also insbesondere die Minimalität von $G$.

    Als weitere Invariante nehmen wir auf, dass die ersten $i$ Pfade (in gieriger Ordnung) von $Q_i$ mit denen von $G$
    übereinstimmen.
    Für $i=0$ gelten alle Voraussetzungen.
    Nehmen wir also an, $Q_{i-1}$ sei zulässig und stimme auf den ersten $i-1$ Pfaden mit $G$ überein.
    Den $i$-ten Pfad von $G$ nennen wir $p=(s_p, t_p)$.

    Für den Fall $p \in Q_{i-1}$ ist $p$ auch bereits der $i$-te Pfad von $Q_{i-1}$, da das Verfahren nach
    gieriger Ordnung vorgeht und $Q_{i-1}$ mit $G$ auf den ersten $i-1$ Pfaden übereinstimmt.
    Setzt man $Q_i \coloneqq Q_{i-1}$, bleiben alle Invarianten erhalten.

    Sonst gilt $p \notin Q_{i-1}$ und die Menge der Pfade $q \in Q_{i-1}$ mit $q >_G p$ ist nicht leer.
    Von diesen Pfaden sei $q$ ein solcher mit kleinstem Startknoten $s_q$, der in $Q_{i-1}$ an $j$-ter Stelle steht
    (insb.\ $j \geq i$).
    Setzt man nun $Q_{i} \coloneqq (Q_{i-1} \cup \{ p \}) \setminus \{ q \} $, so stimmen $Q_{i}$ und $G$ an den
    ersten $i$ Stellen wieder überein und alle Pfade, die in $Q_{i-1}$ an den Stellen $i$ bis $j-1$ stehen, rutschen
    in $Q_i$ eine Stelle weiter an die Positionen $i+1$ bis $j$.
    Insbesondere gilt also $Q_i \leq_G Q_{i-1}$.
    Es bleibt zu zeigen, dass $Q_i$ wieder zulässig ist, wozu die Kapazitäten der einzelnen Kanten betrachtet werden:
    Die Kanten, die links der beiden Anfangsknoten $s_q$ und $s_p$ stehen, sind nicht betroffen, da aufgrund der Minimalität
    von $s_q$ dort nach $q$ keine weiteren Kapazitäten benötigt werden.
    Ist $s_q$ kleiner als $s_p$, so sparen die Kanten zwischen $s_q$ und $s_p$ sogar eine Kapazität ein.
    Ist andersrum $s_p$ kleiner als $s_q$, verletzt $Q_i$ auf den Zwischenkanten trotzdem keine Kapazitäten, da
    hier nach $p$ aufgrund der Minimalität von $s_q$ keine weiteren Pfade eine Kapazität verbrauchen und $p$ vom
    Verfahren akzeptiert wurde, weil bis zum Pfad $p$ keine Kapazität verletzt wurde.
    Die Kanten, bei denen sich $p$ und $q$ überschneiden, spielen offensichtlich keine Rolle und die Kanten
    vom Zielknoten von $p$ bis zum Zielknoten von $q$ benötigen wieder eine Kapazität weniger.
\end{proof}

Daraus folgt, dass das gierige Verfahren das Call-Control-Problem in Ketten optimal löst:
Sei $Q$ eine optimale Lösung, also eine möglichst große, zulässige Teilmenge von Pfaden in $P$, so liefert das gierige
Verfahren nach Lemma~\ref{lem:optimalityGreedyAlgorithm} eine gleichmächtige, sogar minimale Lösung.

Eine einfache Implementierung dieses Verfahrens könnte in $\mathcal O(m \cdot n)$ Zeit erfolgen, wobei $m$ die Anzahl der gegebenen
Pfade und $n$ die Anzahl der Kanten ist, indem einfach für jeden Pfad einzeln an jeder Kante überprüft wird, ob durch
die Hinzunahme die Kapazität überschritten wird.
Jedoch lässt sich dieser Zeitaufwand sogar auf $\mathcal O(n+m)$ verringern, wie wir in den nächsten Abschnitten erkennen werden.
Dabei werden wir zunächst einen Algorithmus kennenlernen, bei dem vorausgesetzt wird, dass alle Kanten die gleiche
Kapazität haben, und diesen danach an unser Ausgangsproblem anpassen.

\subsection{Gieriger Algorithmus für gleiche Kapazitäten von Carlisle und Lloyd}\label{subsec:algorithmusGleicheKapazitäten}
Sei wieder $(V,E)$ eine Kette und $P$ eine Menge von $m$ Pfaden in $(V,E)$, wobei alle Kanten in $E$ nun die
feste Kapazität $C \in \set N$ besitzen.
Dabei können wir ohne Beschränkung der Allgemeinheit von $C \leq m$ ausgehen (sonst könnten wir einfach alle Pfade ohne Gefahr
akzeptieren).
Der Algorithmus, den Carlisle und Lloyd in~\cite{carlisle} beschreiben, hat eine etwas abgewandelte Problemformulierung:
Es wird statt von Pfaden in einer Kette von Intervallen auf der Zahlengeraden gesprochen.
Das Verfahren soll nun möglichst viele dieser Intervalle in $C$ verschiedene Farben färben, wobei sich zwei Intervalle derselben
Farbe nie überschneiden dürfen.
Wie man schnell erkennt, entspricht die größte Menge der gefärbten Intervalle im Ursprungsproblem gerade der größten Teilmenge der Pfade,
in der sich maximal $C$ Pfade an einer Kante überschneiden dürfen, bei der also jede Kante die Kapazität $C$ hat.
Statt also die Intervalle zu färben, reden wir im Folgenden davon, die Pfade entsprechend zu färben.

Der Algorithmus führt zunächst $C$ weitere sogenannte {\em virtuelle Pfade} ein, die in gieriger Ordnung
vor den eigentlichen Pfaden $P$ stehen und jeweils in einer der $C$ Farben gefärbt sind.
Dann werden alle Pfade in gieriger Ordnung verarbeitet.
Dabei wird zu jeder Farbe $c$ der aktuelle {\em Anführer} gespeichert, das heißt, der in gieriger Ordnung größte, bereits
verarbeitete Pfad mit der Farbe $c$.
Die virtuellen Pfade stellen dabei die initialen Anführer der Farben dar.
Der Algorithmus sucht jetzt für jeden Pfad $p$ den größten Anführer, der sich nicht mit $p$ überschneidet.
Ein solcher Pfad heißt {\em optimaler Anführer von $p$}.
Findet er einen solchen, wird $p$ akzeptiert, in die Farbe seines optimalen Anführers gefärbt und damit neuer Anführer
der Farbe.
Findet er keinen, gibt es keine freie Farbe, das heißt das Akzeptieren des Pfades würde eine Kapazität verletzen und der
Pfad wird abgelehnt.
Eine solche Färbung mit $C = 2$, kann man in Abbildung~\ref{fig:k-coloring} sehen.

\begin{figure}[htbp]
	\centering
	\def\svgwidth{220bp}
	\input{k-coloring-v2.pdf_tex}
	\caption{Eine Färbung mit zwei Farben; weiße Pfade sind ungefärbt.}
	\label{fig:k-coloring}
\end{figure}

Speichert man allerdings zu jeder Farbe einfach den jeweiligen Anführer direkt ab, würde das Berechnen eines optimalen
Anführers für jeden Pfad mindestens $\mathcal O(\log C)$ Zeit benötigen und damit würden wir das Ziel einer gesamt-linearen Laufzeit
$\mathcal O(m)$ verpassen.

Stattdessen verwenden Carlisle und Lloyd in ihrem Algorithmus eine spezielle Union-Find-Struktur, die sogenannte
Static-Tree-Set-Union-Struktur aus~\cite{static-tree-set-union}, bei der die möglichen Vereinigungen bereits zu Beginn feststehen und in einem Baum
dargestellt werden können, wodurch $m$ union- und find-Aufrufe bei $n$ Elementen in einer Laufzeit von $\mathcal O(m + n)$ erfolgen können.
Außerdem geht man beim Algorithmus davon aus, dass eine bereits aufsteigend sortierte Liste der Endknoten aller Pfade existiert.
Diese Liste hat also $2\cdot m$ Einträge, d.h.\ ein Punkt kann für verschiedene Pfade öfters vorkommen, dabei sind doppelte Einträge entsprechend der gierigen
Ordnung der zugehörigen Pfade sortiert.

Genauer fügt der Algorithmus in gieriger Ordnung an erster Stelle (noch vor den virtuellen Pfaden) einen weiteren {\em fiktiven Anführer $f$}
ein, der ermöglicht, nicht-akzeptierte Pfade in der Datenstruktur zu behandeln.
Zu Beginn ist dann jeder Pfad in einer eigenen Gruppe der Union-Find-Instanz.
Wir erhalten folgende Invarianten:
Der Repräsentant jeder Gruppe ist immer der kleinste Pfad (in gieriger Ordnung) innerhalb der Gruppe (insbesondere kann man den Repräsentanten einer Union-Find-Gruppe selbst wählen).
Ist ein Pfad noch nicht verarbeitet, so ist er in einer Einzelgruppe - die virtuellen Pfade und der fiktive Anführer
zählen jedoch bereits als verarbeitet.
Jede andere, sogenannte {\em aktive Gruppe}, enthält nur (in gieriger Ordnung) aufeinanderfolgende Pfade.
Der Repräsentant einer aktiven Gruppe ist dabei entweder ein Anführer einer Farbe oder der fiktive Anführer.
Dementsprechend gibt es zu jeder Zeit genau $C+1$ aktive Gruppen, wobei die Gruppe des fiktiven
Anführers immer die Gruppe mit den in gieriger Ordnung kleinsten Pfaden bleibt.

Zunächst berechnet der Algorithmus zu jedem Pfad $p \in P$ den {\em bevorzugten Anführer von $p$}, also den größten Pfad
in gieriger Ordnung, dessen Zielknoten nicht nach dem Anfangsknoten $s_p$ von $p$ steht.
Das kann man mit einfachem Durchlaufen der Liste aller Endknoten in $P$ erreichen, also in $\mathcal O(n)$ Zeit.
Es ist offensichtlich, dass kein optimaler Anführer von $p$ in gieriger Ordnung größer als der bevorzugte Anführer von
$p$ sein kann.

In Abbildung~\ref{fig:union-find-setup} sieht man die entstehende Ausgangssituation für ein Beispiel mit 6 Pfaden.

\begin{figure}[htbp]
	\centering
	\def\svgwidth{250bp}
	\input{union-find-setup.pdf_tex}
	\caption{Die Ausgangssituation: Mit den Pfeilen wird für jeden Pfad der bevorzugte Anführer markiert; $v_1$ und $v_2$ sind die virtuellen Pfade und $f$ ist der fiktive Anführer.}
	\label{fig:union-find-setup}
\end{figure}

Der Algorithmus bearbeitet danach jeden Pfad $p \in P$ nach gieriger Reihenfolge, wobei er jeweils wie folgt vorgeht.
Es wird der bevorzugte Anführer $q$ von $p$ betrachtet:
Ist $\find(q)$, also der Repräsentant der Gruppe von $q$, der fiktive Anführer $f$, so sind alle Pfade in $P$, die kleinergleich dem bevorzugten Anführer $q$
sind und damit Kandidaten für einen optimalen Anführer von $p$ wären, auch in der Gruppe von $f$. Daher kann es keinen optimalen Anführer zu $p$ geben,
da alle Anführer die Repräsentanten der anderen $C$ aktiven Gruppen sind und daher in gieriger Ordnung nach dem bevorzugten Anführer $q$ kommen.
Daher wird $p$ abgelehnt und die Gruppe von $p$ mit der Gruppe des Vorgängers von $p$ in gieriger Ordnung vereinigt.
Die Invarianten bleiben erhalten, da wieder $C+1$ Gruppen unter den verarbeiteten Pfaden existieren mit den gleichen
Anführern.

Ist $\find(q)$ jedoch ein Anführer einer Farbe, so ist es mit Sicherheit der optimale Anführer von $p$, da es der größte
Anführer ist, der noch kleinergleich dem bevorzugten Anführer von $p$ ist (da die Pfade in den Gruppen
aufeinanderfolgend sind).
Also wird $p$ akzeptiert, in dieser Farbe gefärbt und damit neuer Anführer der Farbe.
Da $\find(q)$ nun kein Anführer mehr ist, wird seine Gruppe aufgelöst und mit der Gruppe des Vorgängers von $\find(q)$
vereinigt.
Wieder erhalten wir alle Invarianten.

\begin{figure}[htbp]
	\centering
	\def\svgwidth{280bp}
	\input{union-find-structure.pdf_tex}
	\caption{Der Verlauf der Union-Find-Instanz für das Beispiel aus Abb.~\ref{fig:union-find-setup}}
	\label{fig:union-find-structure}
\end{figure}

In Abbildung~\ref{fig:union-find-structure} sieht man den Verlauf der Union-Find-Instanz für das Beispiel aus Abbildung~\ref{fig:union-find-setup}, dessen Resultat in Abbildung~\ref{fig:k-coloring} dargestellt ist.
Die $i$-te Zeile zeigt dabei den Zustand der Union-Find-Instanz nach Bearbeiten des $i$-ten Pfades.
Jedes Rechteck stellt darin eine Gruppe der Instanz dar.
Der Repräsentant einer Gruppe steht ganz links, wobei Anführer durch Sterne und Färbungen durch Punkte bzw.\ Sterne in schwarz, grau oder weiß (für nicht-akzeptiert) dargestellt werden.
Insbesondere wird erkennbar, dass wir nur Vereinigungen entlang einer Kette machen, was uns ermöglicht, die effizientere Static-Tree-Set-Union-Struktur
aus~\cite{static-tree-set-union} zu verwenden.
Eine genauere Analyse dieses Verfahrens und dessen Laufzeit $\mathcal O(m)$ beschreiben Carlisle und Llyod in~\cite{carlisle}.

\subsection{Gieriger Algorithmus mit willkürlichen Kapazitäten}\label{subsec:anpassenAnWillkürlicheKapazitäten}

Nachdem wir einen effizienten Algorithmus für identische Kapazitäten gefunden haben, wollen wir nun das eigentliche Problem mit
willkürlichen Kapazitäten $c: E \mapsto \set N$ durch geschicktes Anpassen des Algorithmus aus Abschnitt~\ref{subsec:algorithmusGleicheKapazitäten} lösen.
Dazu seien $V=\{0,\dots,n-1\}$ die Knoten der Kette, wobei die Kante $e_i$ die Knoten $i$ und $i+1$ verbinde, und $C \coloneqq \max_{e \in E} c(e)$ die maximale Kapazität aller Kanten.
Die Idee ist es, den Algorithmus für Kanten mit identischer Kapazität $C$ anzuwenden und dabei für jede Kante $e$ die $C - c(e)$
hinzugewonnen Kapazitäten mit Platzhalterpfaden zu befüllen.
Werden alle Platzhalterpfade vom Algorithmus akzeptiert, so können wir sicher sein, dass wir nach Entfernen der
Platzhalterpfade eine optimale Lösung für willkürliche Kapazitäten gefunden haben.
Wir müssen also insbesondere dafür sorgen, dass all unsere Platzhalter eingefärbt werden.
Eine wie im vorigen Abschnitt aufsteigend sortierte Liste der Endknoten aller Pfade berechnen wir nun allerdings selbst mit einem
Aufwand von $\mathcal O(n+m)$, z.B.\ durch Sortieren durch Zählen.
Dabei speichern wir zu jedem Endknotens in der Liste eine Referenz auf seinen zugehörigen Pfad ab.
Insbesondere können wir dann für jeden Eintrag in der Liste entscheiden, ob der Knoten ein Anfangs- oder ein Zielknoten seines zugehörigen Pfades ist.

\begin{figure}[htbp]
	\centering
	\def\svgwidth{250bp}
	\input{dummy_paths.pdf_tex}
	\caption{Platzhalterpfade in schwarz dargestellt (mod. nach~\cite{paper})}
	\label{fig:dummy-paths}
\end{figure}

Wir beschäftigen uns zunächst näher mit dem Hinzufügen der Platzhalter:
Dazu wird die Liste aller Knoten der Kette durchlaufen und gleichzeitig berechnet, wie viele Platzhalterpfade an jedem Knoten
beginnen bzw.\ enden müssen (siehe Abbildung~\ref{fig:dummy-paths}):
Beim ersten Knoten $v_0$ müssen $C - c(e_1)$ Platzhalterpfade beginnen und wir schreiben $(C - c(e_1))$ mal $v_0$ in einen
leeren Keller $K$.
Ist $c(e_i) > c(e_{i+1})$, beginnen beim Knoten $v_{i}$ weitere Platzhalter und $v_i$ wird genau $(c(e_i) - c(e_{i+1}))$ mal in $K$ gelegt.
Ist $c(e_i) < c(e_{i+1})$, so müssen Platzhalterpfade bei $v_i$ enden und es werden $c(e_{i+1}) - c(e_i)$ Elemente aus K geholt, die jeweils als Anfangsknoten mit $v_i$
als Zielknoten einen der Platzhalterpfade bilden.
Beim letzten Knoten $v_{n-1}$ bilden dann alle verbleibenden Knoten aus $K$ als Anfangsknoten mit $v_{n-1}$ als Zielknoten die restlichen Platzhalter.

Da wir allerdings insgesamt eine Laufzeit von $\mathcal O(n+m)$ zum Ziel haben, können wir das beschriebene Verfahren
nicht einfach übernehmen:
Bei starken Schwankungen der einzelnen Kapazitäten kann es hier passieren, dass bis zu $\Omega(m\cdot n)$
Platzhalter hinzugefügt werden müssen, was unsere Ziellaufzeit übersteigt (siehe Abbildung~\ref{fig:dummy-paths-too-many}).
Jedoch wird schnell ersichtlich, dass in solchen Fällen viele Platzhalter unnötigerweise platziert werden:
Hat beispielsweise die Nachfolgekante eines Knoten $v$ eine sehr hohe Kapazität, wobei die Vorgängerkante nur eine sehr
niedrige Kapazität besitzt, so müssten sehr viele Pfade den Anfangsknoten $v$ haben, um die Kapazität der
Nachfolgekante auszunutzen.
Da wir die Pfade bereits kennen, können wir also in vielen Fällen die Kapazität von solchen Nachfolgekanten verringern und
damit Schwankungen in den Kapazitäten etwas ausgleichen.

\begin{figure}[htbp]
	\centering
	\def\svgwidth{250bp}
	\input{dummy_paths_too_many.pdf_tex}
	\caption{Bei jeder zweiten Kante werden $C-1=\Omega(m)$ Platzhalter eingefügt (mod. nach~\cite{paper})}
	\label{fig:dummy-paths-too-many}
\end{figure}

Um diese Erkenntnis umzusetzen, definieren wir eine neue Kapazitätsfunktion $c'$ mit
\[
	c'(e_i) =
	\begin{cases}
		\min(c(e_0), n_0) &\quad\text{für}\ i=0\\
		\min(c(e_i), c'(e_{i-1}) + n_i) &\quad\text{für}\ i \geq 1
	\end{cases}
\]
wobei $n_i$ die Anzahl der Pfade in P mit Anfangsknoten $v_i$ ist.
Diese können wir in $\mathcal O(n+m)$ Zeit berechnen: Dazu gehen wir einmal durch die sortierte Liste der $2m$ Endknoten
aller Pfade und zählen dabei für jeden Knoten $v_i$ der Kette alle Anfangsknoten $v$ in der Liste (überspringe Zielknoten) mit $v = v_i$.
Dies liefert $n_i$, womit wir auch $c'(e_i)$ berechnen können.
Durch das Verwenden von $c'$ statt $c$ wird das Problem auch nicht verändert, da nur Kapazitäten entfernt
werden, die die Pfade $P$ ohnehin nicht nutzen könnten.
Insbesondere ist also jede zulässige Menge auf den Kapazitäten $c$ auch eine zulässige Menge auf den Kapazitäten $c'$.
Das nächste Lemma soll nun aufklären, ob unser Vorgehen die Anzahl an Platzhaltern ausreichend verringern konnte:

\begin{lemma}
    Mit den neuen Kapazitäten $c'$ werden nur noch $\mathcal O(m)$ Platzhalterpfade erzeugt.
\end{lemma}
\begin{proof}
    Wir betrachten den Gesamtzuwachs der Kapazitäten $I = \sum_{i = 0}^{n-2} I_i$ als Summe aller Zuwächse $I_i$ am
    Knoten $v_i$ mit $I_0 = c'(e_0)$ und $I_i = \max\{c'(e_i) - c'(e_{i-1}), 0\}$ für $i \geq 1$.
    Ein Anstieg von $c'$ in $e_i$ um $I_i \in \set N_0$ bedeutet, dass $n_i \geq I_i$, da per Definition
    $c'(e_i) \leq c'(e_{i-1}) + n_i$.
    Insbesondere ist also $I$ beschränkt durch die Anzahl an Pfaden $m$.
    Ein Platzhalterpfad wird außerdem nur dann erzeugt, wenn der Algorithmus auf einen Zuwachs in den Kapazitäten (höchstens $I$)
    oder auf das Ende der Kette (höchstens $C$) stößt.
    Das heißt es werden höchstens $I + C = \mathcal O(m)$ Platzhalterpfade erzeugt.
\end{proof}

Insbesondere gelingt also die Anpassung der Kapazitäten sowie das Auffüllen mit Platzhalterpfaden in $\mathcal O(n+m)$ Zeit.
Nun müssen wir uns nur noch der Herausforderung stellen, beim Lösen des konstruierten Problems mit identischen Kapazitäten alle
Platzhalter zu akzeptieren.
Die Idee dabei ist es, die Platzhalterpfade so früh wie möglich zu akzeptieren, und erst danach die Originalpfade zu
betrachten.

Dazu wird eine Liste $L$ der Endknoten aller Pfade - jetzt mit Platzhalterpfaden - angelegt, wobei wir wieder zu jedem Knoten
eine Referenz auf den zugehörigen Pfad mitspeichern und damit entscheiden können, ob ein Anfangs- oder Zielknoten vorliegt.
Die Einträge der Liste sollen nach Knoten aufsteigend sortiert sein und bei identischen Knoten sollen
Zielknoten vor Anfangsknoten geordnet sein.
Jeder Knoten kommt also genau so oft vor, wie es Pfade mit ihm als einer der beiden Endknoten gibt.
Die gierige Ordnung $\leq_{G}$ erhalten wir, indem wir in der Liste jeden Zielknoten eines Pfades durch den Pfad selbst
ersetzen und die restlichen Knoten verwerfen.

Wir benutzen mit dem fiktiven Anführer und den $C$ virtuellen Pfaden wieder dieselbe Hilfspfade wie in
Abschnitt~\ref{subsec:algorithmusGleicheKapazitäten}, wobei diese in $\leq_G$ wieder vor den restlichen Pfaden stehen.
Für die Berechnung der bevorzugten Anführer jedes Pfades $p$ (also dem in $\leq_G$ größten Pfad $q = (s_q, t_q)$ mit
$t_q \leq s_p$) benötigen wir mit $\leq_G$ ebenfalls einen Zeitaufwand von
$\mathcal O(m)$.
Auch die Union-Find-Struktur bleibt die gleiche und jeder Pfad startet in seiner eigenen Gruppe.
Nun iteriert der Algorithmus durch die Liste $L$ der Endknoten und verarbeitet dabei Platzhalterpfade beim Antreffen vom
zugehörigen Anfangsknoten und Originalpfade beim Antreffen vom zugehörigen Zielknoten.
Die eigentliche Verarbeitung eines Pfades $p$ hat sich aber nicht geändert: Es wird der bevorzugte Anführer $q$ von $p$
betrachtet;
falls $\find(q)$ der fiktive Anführer ist, wird $p$ abgelehnt und die Gruppe von $p$ mit der
Gruppe des Vorgängers von $p$ vereinigt;
andernfalls wird p akzeptiert und in der Farbe von $\find(q)$
gefärbt und die Gruppe von $\find(q)$ mit der Gruppe des Vorgängers von $\find(q)$ vereinigt.

Das nächste Lemma soll nun zeigen, dass das Auffüllen mit Platzhaltern zusammen mit diesem Verfahren eine korrekte
Implementierung des gierigen Verfahrens darstellt:

\begin{lemma}
    Der beschriebene Algorithmus ist eine korrekte Implementierung des gierigen Verfahrens.
\end{lemma}
\begin{proof}
    Wir bezeichnen den oben beschriebenen Algorithmus nun mit $U$.
    Für $U$ haben wir wieder folgende Invariante für die Union-Find-Gruppen:
    Jede Gruppe mit verarbeiteten Pfaden enthält nur in $\leq_G$ aufeinanderfolgende Pfade und der Repräsentant einer
    solchen Gruppe ist entweder ein Anführer einer Farbe oder der fiktive Anführer.
    Andere Gruppen sind Einzelgruppen.

    Es ist leicht zu sehen, dass $U$ wie im vorherigen Abschnitt alle Pfade in $C$ Farben färbt, wobei sich zwei Pfade
    derselben Farbe nie schneiden können.
    Um zu zeigen, dass $U$ alle Platzhalterpfade färbt, nehmen wir an, $U$ würde einen Platzhalterpfad $p$ nicht färben.
    Sei $p$ derjenige Platzhalter mit kleinstem Anfangsknoten, der von $U$ nicht gefärbt wird, und sei $q$ sein bevorzugter Anführer.
    Das bedeutet, dass unmittelbar vor der Bearbeitung von $p$ der Repräsentant $\find(q)$ der fiktive Anführer war.
    Insbesondere gab es unter den $C$ gefärbten Anführern keinen optimalen Anführer von $p$, sondern alle gefärbten Anführer
    haben zu der Zeit einen Zielknoten, der rechts vom Anfangsknoten von $p$ liegt (sonst gäbe es einen optimalen Anführer).
    Da $p$ bereits am Anfangsknoten bearbeitet wird und alle Originalpfade erst am Zielknoten, kann kein Originalpfad einer
    dieser gefärbten Anführer sein, sondern es sind allesamt Platzhalterpfade, die bereits vor $p$ gefärbt worden sein müssen.
    Dementsprechend liegen auf der ersten Kante von $p$ mindestens $C+1$ Platzhalterpfade, was einen Widerspruch zur Konstruktion
    der Platzhalterpfade darstellt.

    Insbesondere berechnet $U$ wieder eine zulässige Teilmenge der Pfade.
    Jetzt müssen wir noch zeigen, dass genau die Originalpfade akzeptiert werden, die auch das gierige Verfahren
    akzeptiert.

    Dazu gehen wir vom Gegenteil aus und betrachten den ersten Originalpfad $p$ in gieriger Ordnung, bei dem die
    Entscheidung unterschiedlich ausgefallen ist.
    Da das gierige Verfahren immer eine minimale Lösung liefert, muss $p$ vom gierigen Verfahren akzeptiert und von
    $U$ abgelehnt worden sein, da die Menge, die $U$ berechnet, ebenfalls zulässig ist.
    Sei $A$ die Menge der Pfade, die unmittelbar vor der Bearbeitung von $p$ (von beiden Verfahren) akzeptiert wurden.
    Da der gierige Algorithmus zusätzlich $p$ akzeptiert hat, wissen wir, dass $A \cup \{p\}$ zulässig ist, was wir
    im Folgenden zum Widerspruch führen:
    Da $U$ den Pfad $p$ am Zielknoten verarbeitete (und $p$ damit der aktuell größte Pfad in gieriger Ordnung
    war), mussten sich zu dieser Zeit alle Anführer von Farben mit $p$ überschnitten haben.
    Dabei sei $l$ der in gieriger Ordnung kleinste Anführer einer Farbe und $e$ die letzte Kante seines Pfades.
    Von dieser wissen wir sicher, dass sie sich mit $p$ überschneidet.

	\begin{figure}[htbp]
		\centering
		\def\svgwidth{270bp}
		\input{proof_chain_greedy_arbitrary.pdf_tex}
		\caption{$c$-gefärbte Pfade sind schwarz. Mit einem Stern gekennzeichnete Pfade sind Anführer ihrer Farbe.
		Der durchgezogene Pfeil zeigt den tatsächlichen Verlauf der Farbe an. $p$ wurde vom gierigen Verfahren akzeptiert und von $U$ abgelehnt.}
		\label{fig:proof-chain-greedy-arbitrary}
	\end{figure}

    Angenommen, es existiere eine Farbe $c$, sodass kein $c$-gefärbter Pfad $e$ enthält.
    Da $l$ der kleinste Anführer ist, existiert ein $c$-gefärbter Pfad $p_1$ links von $e$ (z.B.\ der $c$-gefärbte virtuelle Pfad) und ein $c$-gefärbter Pfad $p_2$
    rechts von $e$ (z.B.\ der $c$-gefärbte Anführer).
    Wählt man, wie in Abbildung~\ref{fig:proof-chain-greedy-arbitrary} beispielhaft skizziert, diese jeweils möglichst nah an $e$, so erkennt man einen Widerspruch:
    Als $p_2$ mit $p_1$ als den scheinbar optimalen Anführer in $c$ gefärbt wurde, war tatsächlich $l$
    ein besserer Anführer von $p_2$, da sein Zielknoten weiter rechts ist.
    Insbesondere hätte $U$ $p_2$ also nicht in $c$ gefärbt.

    Daher besitzen alle $C$ Farben einen Pfad, der $e$ enthält, insgesamt gibt es also $C+1$ Pfade in $A \cup \{p\}$, die
    $e$ enthalten.
    Das ist allerdings ein Widerspruch dazu, dass $A \cup \{p\}$ eine zulässige Menge ist.
\end{proof}

Daraus folgt nun:

\begin{theorem}\label{theorem:greedyAlgorithm}
    Das gierige Verfahren berechnet eine Lösung für \CallControl\ in Kettennetzwerken mit beliebigen Kapazitäten und kann in einer Laufzeit von
    $\mathcal O(n+m)$ implementiert werden, wobei $n$ die Anzahl der Knoten der Kette und $m$ die Anzahl der gegebenen Pfade ist.
\end{theorem}
